{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "random_seed = 33\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"/home/b.cassoli@PTW.Maschinenbau.TU-Darmstadt.de/projects/phd/phd/cip_dmd/notebooks/cip_dmgd_n5/baselines/dataset_baselines_5.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contains features, y contains labels (0 or 1)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Apply random oversampling to the training set\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=random_seed)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameter grid for random search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Regularization penalty\n",
    "    'solver': ['liblinear', 'saga']  # Solver for logistic regression\n",
    "}\n",
    "\n",
    "# Create a random search cross-validation object\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_grid, n_iter=50, cv=3, n_jobs=-1, random_state=random_seed)\n",
    "\n",
    "# Fit the model using random search and cross-validation\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import Random Forest\n",
    "from scipy.stats import randint  # Use randint for integer parameters\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "# Define the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define hyperparameter grid for random search\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10, 20],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 4, 5],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2],  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Create a random search cross-validation object\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=random_seed)\n",
    "\n",
    "# Fit the model using random search and cross-validation\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC  # Import Support Vector Machine\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "# Define the Support Vector Machine model\n",
    "model = SVC()\n",
    "\n",
    "# Define hyperparameter grid for random search\n",
    "param_dist = {\n",
    "    'C': [0.1, 1.0, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel type\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel (only for 'poly' kernel)\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Create a random search cross-validation object\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=random_seed)\n",
    "\n",
    "# Fit the model using random search and cross-validation\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Import k-Nearest Neighbors\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "# Define the k-Nearest Neighbors model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Define hyperparameter grid for random search\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7],  # Number of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski distance metric\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithm used to compute nearest neighbors\n",
    "}\n",
    "\n",
    "# Create a random search cross-validation object\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=random_seed)\n",
    "\n",
    "# Fit the model using random search and cross-validation\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eXtreme Gradient Boosting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier  # Import XGBoost\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define hyperparameter grid for random search\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],  # Number of boosting rounds\n",
    "    'learning_rate': [0.05, 0.1, 0.2],  # Step size shrinkage to prevent overfitting\n",
    "    'max_depth': [2, 3, 4, 5],  # Maximum depth of a tree\n",
    "}\n",
    "\n",
    "# Create a random search cross-validation object\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=random_seed)\n",
    "\n",
    "# Fit the model using random search and cross-validation\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier  # Import MLPClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "# Define the MLPClassifier model\n",
    "model = MLPClassifier()\n",
    "\n",
    "# Define hyperparameter grid for random search\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,)],  # Number of units in hidden layers\n",
    "    'activation': ['relu', 'tanh'],  # Activation function for hidden layers\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # L2 regularization parameter\n",
    "}\n",
    "\n",
    "# Create a random search cross-validation object\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=random_seed)\n",
    "\n",
    "# Fit the model using random search and cross-validation\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "460197fc25d4e493c6950e13f36e16ce3463ab314d0f4d92c3d0997488cc45d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
